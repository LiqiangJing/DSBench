{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-02T05:24:45.900265Z",
     "start_time": "2024-08-02T05:24:43.290171Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import tiktoken\n",
    "import time\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    for line in f:\n",
    "        samples.append(eval(line.strip()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-02T05:24:45.914647Z",
     "start_time": "2024-08-02T05:24:45.904338Z"
    }
   },
   "id": "5df574a898dcc28e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_excel(file_path):\n",
    "    # 读取Excel文件中的所有sheet\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    sheets = {}\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        sheets[sheet_name] = xls.parse(sheet_name)\n",
    "    return sheets\n",
    "\n",
    "def dataframe_to_text(df):\n",
    "    # 将DataFrame转换为文本\n",
    "    text = df.to_string(index=False)\n",
    "    return text\n",
    "\n",
    "def combine_sheets_text(sheets):\n",
    "    # 将所有sheet的文本内容组合起来\n",
    "    combined_text = \"\"\n",
    "    for sheet_name, df in sheets.items():\n",
    "        sheet_text = dataframe_to_text(df)\n",
    "        combined_text += f\"Sheet name: {sheet_name}\\n{sheet_text}\\n\\n\"\n",
    "    return combined_text\n",
    "\n",
    "\n",
    "def find_jpg_files(directory):\n",
    "    jpg_files = [file for file in os.listdir(directory) if file.lower().endswith('.jpg') or file.lower().endswith('.png')]\n",
    "    return jpg_files if jpg_files else None\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "def read_pdf(file_path):\n",
    "    document = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "def read_txt(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def find_excel_files(directory):\n",
    "    jpg_files = [file for file in os.listdir(directory) if (file.lower().endswith('xlsx') or file.lower().endswith('xlsb') or file.lower().endswith('xlsm')) and not \"answer\" in file.lower()]\n",
    "    return jpg_files if jpg_files else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-02T05:24:45.940135Z",
     "start_time": "2024-08-02T05:24:45.917171Z"
    }
   },
   "id": "d95515877156e443",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_LIMITS = {\n",
    "    \"gpt-3.5-turbo-0125\": 16_385,\n",
    "    \"gpt-4-turbo-2024-04-09\": 128_000,\n",
    "    \"gpt-4o-2024-05-13\": 128_000,\n",
    "    \"gpt-4o-mini-2024-07-18\": 128_000\n",
    "}\n",
    "\n",
    "# The cost per token for each model input.\n",
    "MODEL_COST_PER_INPUT = {\n",
    "    \"gpt-3.5-turbo-0125\": 0.0000005,\n",
    "    \"gpt-4-turbo-2024-04-09\": 0.00001,\n",
    "    \"gpt-4o-2024-05-13\": 0.000005,\n",
    "    \"gpt-4o-mini-2024-07-18\": 0.00000015\n",
    "}\n",
    "\n",
    "# The cost per token for each model output.\n",
    "MODEL_COST_PER_OUTPUT = {\n",
    "    \"gpt-3.5-turbo-0125\": 0.0000015,\n",
    "    \"gpt-4-turbo-2024-04-09\": 0.00003,\n",
    "    \"gpt-4o-2024-05-13\": 0.000015,\n",
    "    \"gpt-4o-mini-2024-07-18\": 0.0000006\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-02T05:24:45.951683Z",
     "start_time": "2024-08-02T05:24:45.938376Z"
    }
   },
   "id": "bce091b5a3e40ec1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "api_key = \"Your API key\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "data_path = './data'\n",
    "# model = \"gpt-3.5-turbo-0125\"\n",
    "# model = \"gpt-4-turbo-2024-04-09\"\n",
    "model = \"gpt-4o-2024-05-13\"\n",
    "# model = \"gpt-4o-mini-2024-07-18\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-02T05:24:50.291674Z",
     "start_time": "2024-08-02T05:24:50.127196Z"
    }
   },
   "id": "e7eec792f662253e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "error_cout = 0\n",
    "total_cost = 0\n",
    "for sample in tqdm(samples[0:]):\n",
    "    if len(sample[\"questions\"]) > 0:\n",
    "        start = sample[\"questions\"][0]\n",
    "        end = sample[\"questions\"][-1]\n",
    "        # print(start)\n",
    "        # print(end)\n",
    "        image = find_jpg_files(os.path.join(data_path, sample[\"id\"]))\n",
    "        # if image:\n",
    "        #     image = os.path.join(\"data\", sample[\"id\"], image[0])\n",
    "        \n",
    "        # excel_content = \"\"\n",
    "        excels = find_excel_files(os.path.join(data_path, sample[\"id\"]))\n",
    "        # if excels:\n",
    "        #     for excel in excels:\n",
    "        #         excel_file_path = os.path.join(\"data\",  sample[\"id\"], excel)\n",
    "        #         sheets = read_excel(excel_file_path)\n",
    "        #         combined_text = combine_sheets_text(sheets)\n",
    "        #         excel_content += f\"The excel file {excel} is: \" + combined_text\n",
    "\n",
    "        introduction = read_txt(os.path.join(data_path, sample[\"id\"], \"introduction.txt\"))\n",
    "        questions = []\n",
    "        for question_name in sample[\"questions\"]:\n",
    "            questions.append(read_txt(os.path.join(data_path, sample[\"id\"], question_name+\".txt\")))\n",
    "        \n",
    "        question_content = \"\"    \n",
    "        # print(workbooks)\n",
    "        answers = []\n",
    "        \n",
    "        \n",
    "        for question in tqdm(questions):\n",
    "            start = time.time()\n",
    "\n",
    "            text = f\"The introduction is detailed as follows. \\n {introduction} \\nThe questions are detailed as follows. \\n {question} \\n\\nPlease answer the above question. \"\n",
    "            \n",
    "            assistant = client.beta.assistants.create(\n",
    "            instructions=\"You are a data analyst. I will give  you a background introduction and data analysis question. You must answer the question. If the question is a multi-choice question and you are unsure which one is correct, you must guess an option.  Don't ask me any questions and give me the answer in the response. \",\n",
    "            model=model,\n",
    "            tools=[{\"type\": \"code_interpreter\"}],\n",
    "            # tool_resources={\n",
    "            #   \"code_interpreter\": {\n",
    "            #     \"file_ids\": [train_file.id, test_file.id, sample_file.id]\n",
    "            #   }\n",
    "            # }\n",
    "                )\n",
    "            \n",
    "            print(\"Upload a file with an assistants purpose\")\n",
    "            file_ids = []\n",
    "            if image:\n",
    "                id = client.files.create(\n",
    "                file=open(os.path.join(data_path, sample[\"id\"], image[0]), \"rb\"),\n",
    "                purpose='assistants').id\n",
    "                file_ids.append(id)\n",
    "                # print(id)\n",
    "            \n",
    "            if excels:\n",
    "                for excel in excels:\n",
    "                    file_ids.append(client.files.create(\n",
    "                file=open(os.path.join(data_path,  sample[\"id\"], excel), \"rb\"),\n",
    "                purpose='assistants'\n",
    "              ).id)\n",
    "            \n",
    "            print(\"start a messages\")\n",
    "            attachments = []\n",
    "            print(\"file_ids: \", file_ids)\n",
    "            for file_id in file_ids:\n",
    "                attachments.append({\n",
    "                \"file_id\": file_id,\n",
    "                \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "                })\n",
    "            if len(attachments) > 0:\n",
    "                thread = client.beta.threads.create(\n",
    "                    messages=[\n",
    "                      {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": text,\n",
    "                        \"attachments\": attachments\n",
    "                      }\n",
    "                    ]\n",
    "                  )\n",
    "            else:\n",
    "                thread = client.beta.threads.create(\n",
    "                    messages=[\n",
    "                      {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": text,\n",
    "                      }\n",
    "                    ]\n",
    "                  )\n",
    "            print(\"start client running\")\n",
    "            run = client.beta.threads.runs.create_and_poll(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=assistant.id,\n",
    "                max_prompt_tokens=100000\n",
    "              )\n",
    "            print(\"read  messages\")\n",
    "            \n",
    "            prompt_tokens = run.usage.prompt_tokens \n",
    "            completion_tokens = run.usage.completion_tokens\n",
    "            cost = 0.03 + run.usage.completion_tokens * MODEL_COST_PER_OUTPUT[model] + run.usage.prompt_tokens * MODEL_COST_PER_INPUT[model]\n",
    "              \n",
    "            \n",
    "            messages = client.beta.threads.messages.list(\n",
    "                  thread_id=thread.id\n",
    "                )\n",
    "\n",
    "            # with open(f\"./test_results/gpt4o/{name}_message.txt\", \"w\") as f:\n",
    "            #     f.write(str(messages))\n",
    "            for file_id in file_ids:\n",
    "                client.files.delete(file_id)\n",
    "     \n",
    "      \n",
    "            client.beta.threads.delete(thread.id)\n",
    "            client.beta.assistants.delete(assistant.id)\n",
    "            save_content = str([c.content[0].text.value for c in messages.data])\n",
    "            answers.append({\"id\": sample[\"id\"], \"model\": \"code_interpreter_\"+model, \"input\": prompt_tokens,\n",
    "                            \"output\": completion_tokens, \"cost\": cost, \"time\": time.time()-start, \"response\": save_content})\n",
    "            total_cost += cost\n",
    "            print(\"Total cost: \", total_cost)\n",
    "            # break\n",
    "        save_path = os.path.join(\"./evaluation/save_process\", \"code_interpreter_\"+model)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        with open(os.path.join(save_path, sample['id']+\".json\"), \"w\") as f:\n",
    "            for answer in answers:\n",
    "                json.dump(answer, f)\n",
    "                f.write(\"\\n\")\n",
    "                \n",
    "        # break 36\n",
    "end = time.time()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8df1566c7956e188",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "messages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa9aa95d9a81a72e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ffb65de76dfd89b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
